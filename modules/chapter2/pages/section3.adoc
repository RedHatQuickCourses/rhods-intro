= Data Connections

// Description
// Describe the concept of a data connection and why you need it
// Concepts
// S3 data connections
// Local cluster storage

In data science, AI, and ML environments, the availability of data is a key factor for the success of the project.
For simple projects, where a relatively small amount of data is used, you can load data by uploading files to the workbench via JuypterLab, or by making database queries from your notebooks.

More complex projects, however, involve larger datasets.
Depending on the dataset size, uploading files or querying databases might not be a feasible solution.
Storing the data directly in your code repository is not recommended either, due to the overload that this can cause in your repository.
In fact, many source control systems include file size limits.

The recommended approach is to store the data in a dedicated storage system, and download the data into your workbench when you need it.
Similarly, trained models can result in large files when you export them, so you can upload the model files to the storage system.

RHODS introduces the concept of _data connection_ to define a set of configuration values that you can use to connect to storage systems.
You can use the external storage to store the data for training, but also your trained models.

[IMPORTANT]
====
Do not confuse data connections with cluster storage.

Cluster storage provides persistent storage for your workbench, by using PVCs in your cluster.
Cluster storage is used to persist your progress in the workbench.

Data connections are a set of configuration values that you can use to connect to S3, in order to read data and save models.
====

== S3

A data connection is a collection of key/value configuration values for connecting to Amazon Web Services (AWS) Simple Storage Service (S3).
When you associate a data connection to a workbench, RHODS injects this key/value pairs as configuration values into the workbench.

You can use a data connection to connect with any storage system that exposes an S3 API, such as OpenShift Data Foundation, IBM Cloud Object Storage, and AWS S3.

[IMPORTANT]
====
When using a data connection in a workbench, the data connection does not open a connection from the workbench to AWS S3.

You are responsible for using the environment variables of the data connection in the notebook to connect to S3
====

Similarly, you should store your trained models in the S3 that corresponds to the data connection.
Storing your models in the data connection enables you to use Model Serving.
Model Serving downloads the model files from S3 by using a data connection.

== Other Data Storage

If you need access to data available in other systems, such as Kafka, MongoDB, then you must use the necessary libraries to retrieve data from those systems into your notebook.

// Notes
// What is a data connection? Why do you need it?
// What are the different types of data connections (AWS S3 etc)
// Screenshot walkthrough of AWS S3 data connection creation and deletion
// Can data connections be shared?
// Adding data connections to existing workbenches
// [Trevor] I'm not sure what Local cluster storage has to do with the data connections features and I don't see anything in the notes discussing anything related to storage.  It seems like "local cluster storage" would most likely fall under the topic of adding storage to a workbench in the previous section more so than the data connections section.
// [Andres] - Maybe this has to do with the Local Storage Operator (LSO) or the NFS Storage provisioner, but I'm not sure.
// [Trevor] - A data connection is just a k8s secret with a pre-defined format.  No provisioning of storage in the cluster is needed.  I would assume that some form of s3 compatible storage would already be provisioned for the user for the exercises. I'm unsure if the RHODS Dashboard uses the users permissions in the NS to determine if they can create a data connection (i.e. secret) or if it allows users to create data connections as long as they have access to the project.  That might be something worth checking into.
// Verifying data connections in Notebooks
// Creating an Amazon S3 client using notebook cells
// Listing available Amazon S3 buckets using notebook cells
// Listing files in available Amazon S3 buckets using notebook cells
// Uploading and downloading files from available Amazon S3 buckets using notebook cells
// [Jaime] - When a data connection is linked with a workbench, RHODS injects the S3 config values as environment variables into the workbench. From that point, the developer must use these variables inside the workbench (in a notebook) and pass them to boto3 or any other lib. 
// If no data connection is created, then developers can still test the connection by hardcoding the S3 config values into the notebook, but that, of course, is a security risk, as s3 config can be easily leaked to the git repository.
